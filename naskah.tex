
======

review control achitecture-jurnal paper/conference

The control architectures could be classified into three categories: Deliberative (Centralized) navigation, Reactive (Behaviour-based) navigation and hybrid (Deliberative - Reactive) navigation.

behavior-based architectures are described as they were originally
designed. The architectures are Subsumption, Action Selection Dynamics, Motor Schema and Process Description Language.


Subsumption architecture advocates the competitive
selection of behaviours, while the motor schemas rely on the use of cooperative coordination. Motor schema provides an ability to simultaneously use the outputs of more than one behavior with capturing their particular influence on overall output (Vuković and Miljković, 2009).

The overall advantages of behaviour-based navigation systems are:
i) Their ability to build a navigation system in an incremental way of layer upon layer.
ii) Their quick reaction to the unknown and dynamic environment. 
iii) They do not require modelling and storing the whole model of the environment. 
iv) There is less computation and shorter delay between perception and action. 
v) And they are more robust and reliable which means in case of a behaviour unit failure, the other units continue the tasks.

The drawbacks of behaviour-based control are as follows:
i) Difficulty in coordination among the behaviours, the interaction between the system and environment is difficult and less predictable.
 ii) Behaviours are low level so they do not reflect high level tasks. 
 iii) Lack of planning module could be not appropriate for some complicated tasks.
 
 
 
 Behavior-based control layer. Design of a behavior-based control system
which will be contained in the overall control architecture with the purpose of accomplishing simple tasks. A task is intended as one of the phases in which a mission can be divided. It is assumed that the sequential achievement of a set of tasks entails the achieveb.wment of the mission. The behavior-based control system must assure the safety of
 the robot while demonstrating a high control performance.
 
 Reinforcement Learning-based behaviors. Integration of a reinforcement learning algorithm in the control architecture. This learning theory
 will be applied to the acquisition of the internal structure of a robot
 behavior. The purpose of using Reinforcement Learning is to reduce
 the required human work in the development of a new robot behavior.
 Instead of implementing the action-decision rules, the designer need
 only to define the goal of the behavior.
 

 
 Reinforcement learning
 Reinforcement learning (RL) is a class of learning algorithm where a
 scalar evaluation (reward) of the performance of the algorithm is available from the interaction with the environment. The goal of a RL
algorithm is to maximize the expected reward by adjusting some value
 functions. This adjustment determines the control policy that is being
 applied. The evaluation is generated by a reinforcement function which
 is located in the environment. Chapter 4 gives a detailed description
 of Reinforcement Learning and its application to robotics. Main references about RL are [Kaelbling et al., 1996, Sutton and Barto, 1998].